{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy #pip install tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob_de import TextBlobDE as TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    text_file= open(path,'r')\n",
    "    file_content = text_file.read()\n",
    "    return file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter API Key auslesen und authentifizieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Twitter Api Keys From File\n",
    "file_content = load_file('../../../twitter-files/credentials.txt')\n",
    "sentences = file_content.split(\"\\n\")\n",
    "sentences = [s.split(\"=\") for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentifizierung\n",
    "consumer_key = sentences[0][1]\n",
    "consumer_secret = sentences[1][1]\n",
    "access_token = sentences[2][1]\n",
    "access_token_secret = sentences[3][1]\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigene Timeline ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigene Twitter Timeline ausgeben\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets zu einem Hashtag auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @kardasiapat: #Maas: #Chemnitz schadet deutschem Image https://t.co/aT6XNOFQsT\n",
      "\n",
      "Falsch, die #Groko schadet Deutschland und den Millionen…\n",
      "\n",
      "\n",
      "RT @freie_presse: Wölfe vor Marx-Monument in #Chemnitz: Kunstaktion „Die Wölfe sind zurück“ von @OpolkaRainer gegen Hetze und Gewalt. https…\n",
      "\n",
      "\n",
      "RT @PatrickGensing: #Faktencheck: #Chemnitz-Videos auf dem Prüfstand #verifikation \n",
      " https://t.co/xXwPVbU8Vk\n",
      "\n",
      "\n",
      "@Tanja1887 @fschmidt77 @AntifaPinneberg @Timonsky_pan @PaulLempges @wagnchri @ffgr_zentrale @freeze1887 @qnuke9… https://t.co/I9typN6oUE\n",
      "\n",
      "\n",
      "RT @Hartes_Geld: Genial: Zu den Mehrfach-Identitäten des \"Opfers\" der Hetzjagd in #Chemnitz hat das ZDF/ @HeutePlus extra \"gecheckt\", dass…\n",
      "\n",
      "\n",
      "RT @FHackenbruch: Raed Saleh (SPD) eröffnet aktuelle Stunde im #AGH zu Vorkommnissen in #Chemnitz mit Attacke gegen AfD: „Ihre Partei hat d…\n",
      "\n",
      "\n",
      "RT @reinboth: Alter. In #Chemnitz und #Köthen wird bei Hitlergrüßen, SS-Runen und Aufrufen zum Rassenkrieg nicht eingeschritten - und in #B…\n",
      "\n",
      "\n",
      "RT @GodCoder: In #Chemnitz waren 581 Polizisten um die fdGO zu verteidigen. Im #Hambacher-Forst sind 2100 Polizisten, um Interessen der Ind…\n",
      "\n",
      "\n",
      "RT @MartinaRenner: Schön, dass @BMI_Bund erst @dpa mit Papier von #Maaßen zu #Chemnitz versorgt, bevor es dem Innenausschuss zur Vorbereitu…\n",
      "\n",
      "\n",
      "RT @GrueneFraktionB: #Chemnitz erinnert uns daran, dass wir täglich für Freiheit, Demokratie und gesellschaftlichen Frieden kämpfen müssen.…\n",
      "\n",
      "\n",
      "Rassistische Hetzer in #Chemnitz abwiegeln, Zahlen aus dem VS-Bericht vertraulich an die #AfD weiter geben, der… https://t.co/TX4tvbaj1Q\n",
      "\n",
      "\n",
      "RT @LinksfraktionB: '@UdoWolfMdA an #Dregger. #CDU: \"Mit dieser unsäglichen Gleichsetzung von Rechts und Links angesichts der Bilder von #C…\n",
      "\n",
      "\n",
      "Gerade entdeckt: Starkes Interview von @armin_schuster zur Situation in #Chemnitz und der Gefahr durch den Extremis… https://t.co/H4UTitkxTJ\n",
      "\n",
      "\n",
      "RT @watch_union: Im #HambacherForst kommt ein SEK zum Einsatz. Schon interessant, was gegen Linke aufgefahren wird - während Nazis in #Chem…\n",
      "\n",
      "\n",
      "RT @DrDavidBerger: Ein völlig nichtssagender Bericht von @Frontal21 soll Merkel retten? Da war das Propaganda-TV der DDR ja glaubwürdiger!…\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "public_tweets = api.search('#chemnitz', rpp=20, lang=\"de\")\n",
    "x = []\n",
    "for tweet in public_tweets:\n",
    "    x.append(tweet.text)\n",
    "    print(tweet.text + \"\\n\\n\")\n",
    "    \n",
    "#Sentiment Analysis on Tweets\n",
    "# analysis = TextBlob(tweet.text)\n",
    "# print(analysis.sentiment)\n",
    "# print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @DrDavidBerger: Ein völlig nichtssagender Bericht von @Frontal21 soll Merkel retten? Da war das Propaganda-TV der DDR ja glaubwürdiger!…'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet zu einer Tweet ID auslesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mirabellen frisch aus dem Garten ❤ #obst #ernte #healthy #herbst #yummy #mirabellen http://t.co/u5poZLbewJ\n"
     ]
    }
   ],
   "source": [
    "tweet = api.get_status(\"375157302846062593\")\n",
    "print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets herunterladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets herunterladen\n",
    "tweet_content = []\n",
    "for tweet_id in range(75):\n",
    "#     print(tweet_corpus[\"Tweet ID\"][tweet_id])\n",
    "    try:\n",
    "        tweet_content.append(api.get_status(tweet_corpus[\"Tweet ID\"][tweet_id]).text)\n",
    "    except Exception:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets herunterladen\n",
    "tweet_content = []\n",
    "for tweet_id in range(75):\n",
    "    tweet_content.append(api.get_status(tweet_corpus[\"Tweet ID\"][tweet_id]).text)\n",
    "\n",
    "print(tweet_content[0])\n",
    "print(len(tweet_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
